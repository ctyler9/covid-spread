{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixer(filename_list):\n",
    "    \n",
    "    df1 = pd.read_csv('../data/{0}'.format(filename_list[0]))\n",
    "    if len(filename_list) > 1:\n",
    "        for file in filename_list[1:]:\n",
    "            new_df = pd.read_csv('../data/{0}'.format(file))\n",
    "            df1 = pd.concat([df1, new_df])\n",
    "    \n",
    "    data = df1.reset_index()\n",
    "    data = data.fillna(0)\n",
    "    del data['index']\n",
    "            \n",
    "    mapper = pd.read_csv(\"../data/case_data.csv\")\n",
    "    \n",
    "    del data['Unnamed: 0']\n",
    "    data.set_index(\"county\")\n",
    "    \n",
    "    data2 = pd.melt(data, id_vars=['county'])\n",
    "    data3 = data2.rename(columns={'variable':'date', 'county':'FIPS', 'value':'cases'})\n",
    "    data3['FIPS'] = data3['FIPS'].apply(lambda x: str(x) if len(str(x)) == 5 else str(x))\n",
    "    data4 = data3\n",
    "    mapper['FIPS'] = mapper['FIPS'].apply(lambda x: str(x).split(\".\")[0])\n",
    "    data4 = data4.merge(mapper, on='FIPS')\n",
    "    \n",
    "    del data4['Country_Region']\n",
    "    del data4['Last_Update']\n",
    "    del data4['Lat']\n",
    "    del data4['Long_']\n",
    "    del data4['Confirmed']\n",
    "    del data4['Deaths']\n",
    "    del data4['Recovered']\n",
    "    del data4['Active']\n",
    "    del data4['Combined_Key']\n",
    "    \n",
    "    data5 = data4.sort_values('date')\n",
    "    data5 = data5.rename(columns={'FIPS':'fips', 'Admin2':'county', 'Province_State':'state'})\n",
    "    ir = filename_list[0].split(\"_\")[2]\n",
    "    rr = filename_list[0].split(\"_\")[3]\n",
    "    \n",
    "    #get historical data from nyt\n",
    "    historical_data = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\")\n",
    "    del historical_data['deaths']\n",
    "    #print(historical_data['state'].unique())\n",
    "    #format fips correctly\n",
    "    #historical_data['fips'] = historical_data['fips'].apply(lambda x: str(x) if len(str(x)) == 5 else \"0\"+str(x))\n",
    "    historical_data['fips'] = historical_data['fips'].apply(lambda x: str(x).split(\".\")[0])\n",
    "    #only include the fips ids we're looking at for this viz\n",
    "    historical_data = historical_data.loc[historical_data['fips'].isin(list(data5['fips']))]\n",
    "    historical_data.reset_index()\n",
    "    indexNames = historical_data[ historical_data['fips'] == 'nan' ].index\n",
    "    historical_data.drop(indexNames, inplace=True)\n",
    "    #filter dates by after a date\n",
    "    historical_data.sort_values('date')\n",
    "    historical_data['date'] = pd.to_datetime(historical_data['date'])\n",
    "    historical_data = historical_data[(historical_data[\"date\"] >= '2020-04-18') & (historical_data[\"date\"] <= '2020-04-21')]\n",
    "    historical_data['date'] = historical_data['date'].apply(lambda x: str(x).split(\" \")[0]) \n",
    "    #decrease cases by factor of 1000 in order to match our predicted data\n",
    "    historical_data['cases'] = historical_data['cases'].apply(lambda x: x/1000)\n",
    "    #compile together\n",
    "    data6 = pd.concat([historical_data,data5], ignore_index=True)\n",
    "    data6.sort_values(by=['date'])\n",
    "    data6['fips'] = data6['fips'].apply(lambda x: \"0\" + x if len(x) < 5 else x)\n",
    "    \n",
    "    #add population data:\n",
    "    population_df = pd.read_csv(\"../data/census_data.csv\", encoding=\"ISO-8859-1\")\n",
    "    del population_df['SUMLEV']\n",
    "    del population_df['REGION']\n",
    "    del population_df['DIVISION']\n",
    "    del population_df['STATE']\n",
    "    del population_df['COUNTY']\n",
    "    del population_df['CENSUS2010POP']\n",
    "    pop = population_df.rename(columns={'STNAME':'state', 'CTYNAME':'county', 'POPESTIMATE2019':'population'})\n",
    "    pop['county'] = pop['county'].str.split(\" Count\", expand=True)[0]\n",
    "        \n",
    "    data7 = data6.merge(pop, on=['state', 'county'])\n",
    "    means = data7.groupby(['state'])['population'].mean()\n",
    "    data7['population'] = data7['population'].fillna(means)\n",
    "    data7['date'] = pd.to_datetime(data7['date'])\n",
    "    data7 = data7.sort_values(by=['date', 'cases', 'fips'],ascending=True)\n",
    "    print(data7)\n",
    "    \n",
    "    data7.to_csv(\"../data/combined_{0}_{1}\".format(ir, rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Elise/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cases      county       date   fips          state  population\n",
      "420   0.001       Essex 2020-04-18  50009        Vermont        6163\n",
      "90    0.002   Aroostook 2020-04-18  23003          Maine       67055\n",
      "210   0.002  Washington 2020-04-18  23029          Maine       31379\n",
      "260   0.002        Coos 2020-04-18  33007  New Hampshire       31563\n",
      "440   0.003  Grand Isle 2020-04-18  50013        Vermont        7235\n",
      "..      ...         ...        ...    ...            ...         ...\n",
      "29   15.000  Litchfield 2020-04-27  09005    Connecticut      180333\n",
      "109  20.000  Cumberland 2020-04-27  23005          Maine      295003\n",
      "19   26.000    Hartford 2020-04-27  09003    Connecticut      891720\n",
      "9    38.000   Fairfield 2020-04-27  09001    Connecticut      943332\n",
      "369  41.000  Providence 2020-04-27  44007   Rhode Island      638931\n",
      "\n",
      "[520 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Elise/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:60: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester_full = [\"output_Connecticut_0.001_0.06.csv\",\"output_Maine_0.001_0.06.csv\", \"output_Vermont_0.001_0.06.csv\", \"output_New Hampshire_0.001_0.06.csv\", \"output_Rhode Island_0.001_0.06.csv\"]\n",
    "tester_full2 = [\"output_Connecticut_0.003_0.08.csv\",\"output_Maine_0.003_0.08.csv\", \"output_Vermont_0.003_0.08.csv\", \"output_New Hampshire_0.003_0.08.csv\", \"output_Rhode Island_0.003_0.08.csv\"]\n",
    "tester_full3 = [\"output_Connecticut_0.01_0.8.csv\",\"output_Maine_0.01_0.8.csv\", \"output_Vermont_0.01_0.8.csv\", \"output_New Hampshire_0.01_0.8.csv\", \"output_Rhode Island_0.01_0.8.csv\"]\n",
    "\n",
    "fixer(tester_full3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_combiner(filename_list):\n",
    "    df1 = pd.read_csv('../data/{0}'.format(filename_list[0]))\n",
    "    df1['rate'] = filename_list[0].split(\"_\")[1] + \"_\" + filename_list[0].split(\"_\")[2].split(\".c\")[0]\n",
    "#     df1['rr'] = filename_list[0].split(\"_\")[2].split(\".c\")[0]\n",
    "    if len(filename_list) > 1:\n",
    "        for file in filename_list[1:]:\n",
    "            new_df = pd.read_csv('../data/{0}'.format(file))\n",
    "            new_df['rate'] = file.split(\"_\")[1] + \"_\" + file.split(\"_\")[2].split(\".c\")[0]\n",
    "            #new_df['rr'] = file.split(\"_\")[2].split(\".c\")[0]\n",
    "            df1 = pd.concat([df1, new_df])\n",
    "    \n",
    "    data = df1.reset_index()\n",
    "    data = data.fillna(0)\n",
    "    del data['index']\n",
    "    del data['Unnamed: 0']\n",
    "\n",
    "    data['fips'] = data['fips'].apply(lambda x: \"0\" + str(x) if len(str(x)) < 5 else str(x))\n",
    "    data = data.sort_values(by=['date'])\n",
    "    print(data)\n",
    "    data.to_csv(\"../data/total_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cases        county        date   fips          state  population  \\\n",
      "0      0.001         Essex  2020-04-18  50009        Vermont        6163   \n",
      "1062   0.035  Androscoggin  2020-04-18  23001          Maine      108277   \n",
      "1061   0.034       Windsor  2020-04-18  50027        Vermont       55062   \n",
      "1060   0.031    Washington  2020-04-18  50023        Vermont       58409   \n",
      "1059   0.030       Carroll  2020-04-18  33003  New Hampshire       48910   \n",
      "...      ...           ...         ...    ...            ...         ...   \n",
      "1010  28.000       Orleans  2020-04-27  50019        Vermont       27037   \n",
      "1011  33.000      Sullivan  2020-04-27  33019  New Hampshire       43146   \n",
      "1012  34.000    Bennington  2020-04-27  50003        Vermont       35470   \n",
      "988    0.000  Androscoggin  2020-04-27  23001          Maine      108277   \n",
      "1559  41.000    Providence  2020-04-27  44007   Rhode Island      638931   \n",
      "\n",
      "            rate  \n",
      "0     0.001_0.06  \n",
      "1062    0.01_0.8  \n",
      "1061    0.01_0.8  \n",
      "1060    0.01_0.8  \n",
      "1059    0.01_0.8  \n",
      "...          ...  \n",
      "1010  0.003_0.08  \n",
      "1011  0.003_0.08  \n",
      "1012  0.003_0.08  \n",
      "988   0.003_0.08  \n",
      "1559    0.01_0.8  \n",
      "\n",
      "[1560 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "total_combiner(['combined_0.001_0.06.csv', 'combined_0.003_0.08.csv', 'combined_0.01_0.8.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
